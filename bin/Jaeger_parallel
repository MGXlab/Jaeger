#!/usr/bin/env python

"""
Copyright 2022 R. Y. Wijesekara - University Medicine Greifswald, Germany

Identifying phage genome sequences concealed in metagenomes is a 
long standing problem in viral metagenomics and ecology. 
The Jaeger approach uses homology-free machine learning to identify
 both phages and prophages in metagenomic assemblies.

"""

import subprocess
import os
import concurrent.futures
import time
from tqdm import tqdm
import argparse
import pandas as pd
from collections import defaultdict
from importlib.metadata import metadata, version


def dir_path(path):
    '''checks path and creates if absent'''
    if os.path.isdir(path):
        return path
    else:
        os.mkdir(path)
        return path


def file_path(path):
    '''checks if file is present'''
    if os.path.isfile(path):
        return path
    else:
        raise argparse.ArgumentTypeError(f"ERROR:{path} is not a valid file")
        
def cmdparser():
    '''cmdline argument parser'''
    parser = argparse.ArgumentParser(description=f'\n## Jaeger {version("jaeger-bio")} (yet AnothEr phaGe idEntifier) Deep-learning based bacteriophage discovery (parallel execution) \nhttps://github.com/Yasas1994/Jaeger.git',
    usage=argparse.SUPPRESS,formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("-i","--input",
                        type=file_path,
                        required=True,
                        help="path to a file containing a list of input file paths")
    parser.add_argument("-o","--outpath", 
                        type=str,
                        required=True,
                        help='path to output directory')
    parser.add_argument("-of","--ofasta", 
                        type=str,
                        required=False,
                        help='path to output fasta file')
    # parser.add_argument("--cutoff", 
    #                     type=float,
    #                     required=False,
    #                     default=2.9,
    #                     help='fasta output cutoff score')
    parser.add_argument("--fsize", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="length of the sliding window (value must be 2^n). default:2048")

    parser.add_argument("--stride", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="stride of the sliding window. default:2048 (stride==fsize)")
    parser.add_argument("--batch", 
                        type=int,
                        nargs='?',
                        default=128, 
                        help="parallel batch size, set to a lower value if your gpu runs out of memory. default:128")
    parser.add_argument('--getalllogits',
                       action="store_true",
                        help="return position-wise logits for each prediction window as a .npy file" )
    parser.add_argument("--getalllabels", 
                        action="store_true",
                        help="get predicted labels for Non-Viral contigs. default:False")
    parser.add_argument("--meanscore",
                        action="store_true", 
                        help="output mean predictive score per contig. deafault:True")
    parser.add_argument("--fragscore", 
                        action="store_true", 
                        help="output percentage of perclass predictions per contig. deafault:True")
    misc = parser.add_argument_group('Misc. Options')

    misc.add_argument('-v', '--verbose', action="count", default=2,
                  help='Verbosity level : 1 warning, 2 info, 3 debug, (default info)')

    misc.add_argument('-f', '--overwrite', action="store_true", help='Overwrite existing files')   

    parser.add_argument("-mw","--maxworkers", 
                        type=int,
                        required=False,
                        default=4,
                        help='set the maxium number of workers for a single GPU')
    
    parser.add_argument("--ngpu",
                        type=int,
                        required=False,
                        default=2,
                        help='set the number of GPUs to use')
    return parser.parse_args()
    
class SubprocessPool:
    def __init__(self, max_workers_per_gpu, num_gpus,total_commands,commands):
        self.max_workers_per_gpu = max_workers_per_gpu
        self.num_gpus = num_gpus
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers_per_gpu*num_gpus)
        self.futures = {i:[] for i in range(num_gpus)}
        self.counter = {i:0 for i in range(num_gpus)}
        self.pending_commands = []
        self.pbar = tqdm(total=total_commands, position=0) 
        self.done = 0
        self.total = total_commands
        self.pending_commands=commands

    def submit(self, command):
        #check which gpu is vacant
        #print(self.counter)
        for key,value in self.counter.items():
            #print(key,value)
            if value < self.max_workers_per_gpu:
                #edit the command and specify the physicalid of the gpu to use
                command_ = command + f" --virtualgpu --physicalid {key}"
                future = self.executor.submit(self._run_subprocess, command_)
                self.futures[key].append(future)
                self.counter[key]+=1
                break
        #if value == self.max_workers_per_gpu and key == self.num_gpus:
            #if all workers are busy, append to pending commands
            

    def _run_subprocess(self, command):
        try:
            subprocess.run(command, shell=True, check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"Error executing '{command}': {e}")
        except Exception as e:
            print(f"An error occurred: {e}")

    def monitor_pool(self):
        while True:
            for key,values in self.futures.items():
                #print(key,values,self.pending_commands)
                for future in values:
                    if future.done():
                        self.futures[key].remove(future)
                        self.counter[key]-=1
                        self.pbar.update(1)
                        self.done += 1
            if self.counter[key] < self.max_workers_per_gpu and len(self.pending_commands) > 0:
                # Replenish the pool by submitting new tasks
                self.submit(self.pending_commands.pop(0))
                
            elif self.done == self.total:
                self.executor.shutdown() #shutdown the pool
                break #exit the loop
            time.sleep(1)  # Adjust sleep duration as needed
            

    def close(self):
        self.executor.shutdown()
    
if __name__ == '__main__':
    args = cmdparser()
    input_paths = [line.rstrip('\n') for line in open(args.input).readlines()]
    
    NUMBER_OF_GPUS = args.ngpu
    MAX_WORKERS_PER_GPU = args.maxworkers
    
    NUMBER_OF_TASKS = len(input_paths)
    progress_bar = tqdm(total=NUMBER_OF_TASKS)
    
    
    template = ""
    if args.ofasta:
        template+= f' -of {args.ofasta}'
    # if args.cutoff:
    #     template+= f' --cutoff {args.cutoff}'
    if args.fsize:
        template += f' --fsize {args.fsize}'
    if args.stride:
        template += f' --stride {args.stride}'
    if args.batch:
         template += f' --batch {args.batch}'
    if args.getalllogits:
         template += f' --getalllogits '
    if args.getalllabels:
         template += f' --getalllabels '
    # if args.verbose:
    #      template += f' --verbose {args.verbose} '  
    if args.overwrite:
         template += f' --overwrite '    
    
    
    ALL_COMMANDS = [f"Jaeger -i {i} -o {args.outpath} {template}" for i in input_paths]
    pool = SubprocessPool(MAX_WORKERS_PER_GPU, NUMBER_OF_GPUS, NUMBER_OF_TASKS,ALL_COMMANDS)

    try:
        pool.monitor_pool()
    except KeyboardInterrupt:
        pool.close()
