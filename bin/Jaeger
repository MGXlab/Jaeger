#!/usr/bin/env python
"""
Copyright 2022 R. Y. Wijesekara

Identifying phage genome sequences concealed in metagenomes is a 
long standing problem in viral metagenomics and ecology. 
The Jaeger approach uses homology-free machine learning to identify
 both phages and prophages in metagenomic assemblies.
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
import sys
import psutil
import argparse
import logging
import numpy as np
from importlib.resources import files
from importlib.metadata import metadata, version
from tqdm import tqdm
from functools import partialmethod
import json
import h5py

from Bio import SeqIO
import pandas as pd
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.layers import InputSpec
import tensorflow.keras.backend as K
#from tensorflow.data import Dataset, TextLineDataset, TFRecordDataset


from jaegeraa.nnlib.layers import WRes_model, create_jaeger_model
from jaegeraa.nnlib.cmodel import JaegerModel
from jaegeraa.utils import get_compressed_file_handle, dir_path, file_path, fasta_entries, get_device_name, create_logger, remove_directory
from jaegeraa.preprocessing import fasta_gen,process_string, process_string_gen2
from jaegeraa.postprocessing import update_dict, write_output, logits_to_df, plot_scores, segment, get_cordinates



def cmdparser():
    '''cmdline argument parser'''
    parser = argparse.ArgumentParser(description=f'\n\n## Jaeger {version("jaeger")} (yet AnothEr phaGe idEntifier) Deep-learning based bacteriophage discovery \nhttps://github.com/Yasas1994/Jaeger.git',
    usage=argparse.SUPPRESS,formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("-i","--input",
                        type=file_path,
                        required=True,
                        help="path to input file")
    parser.add_argument("-o","--output", 
                        type=str,
                        required=True,
                        help='path to output directory')
    parser.add_argument("--fsize", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="length of the sliding window (value must be 2^n). default:2048")
    parser.add_argument("--stride", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="stride of the sliding window. default:2048 (stride==fsize)")
    parser.add_argument("-m", "--model", 
                            choices=['default', 'experimental_1', 'experimental_2'],
                            default='default', 
                            help="select a deep-learning model to use. default:default")
    parser.add_argument("-p", "--prophage", 
                            action="store_true",
                            default=False, 
                            help="extract and report prophage-like regions. default:False")
    parser.add_argument("-s", "--sensitivity", 
                            type=float,
                            nargs='?',
                            default=1.5, 
                            help="sensitivity of the prophage extraction algorithm (between 0 - 4). default: 1.5 ")
    parser.add_argument("--lc", 
                            type=int,
                            nargs='?',
                            default=500000, 
                            help="minimum contig length to run prophage extraction algorithm. default: 500000 bp")
    parser.add_argument("--batch", 
                        type=int,
                        nargs='?',
                        default=96, 
                        help="parallel batch size, set to a lower value if your gpu runs out of memory. default:96")
    parser.add_argument("--workers", 
                        type=int,
                        nargs='?',
                        default=4, 
                        help="number of threads to use. default:4")
    parser.add_argument('--getalllogits',
                       action="store_true",
                        help="return position-wise logits for each prediction window as a .npy file" )
    parser.add_argument('--usecutoffs',
                       action="store_true",
                        help="use cutoffs to obtain the class prediction" )
    group = parser.add_mutually_exclusive_group()

    group.add_argument("--cpu", 
                        action="store_true",
                        help="ignore available gpus and explicitly run jaeger on cpu. default: False")

    parser.add_argument("--virtualgpu",
                    action="store_true",
                    help='create and run jaeger on a virtualgpu. default: False')
    parser.add_argument("--physicalid",
                    type=int,
                    nargs='?',
                    default=0,
                    help='sets the default gpu device id (for multi-gpu systems). default:0')
    parser.add_argument("--getalllabels", 
                        action="store_true",
                        help="get predicted labels for Non-Viral contigs. default:False")
    misc = parser.add_argument_group('Misc. Options')

    misc.add_argument('-v', '--verbose', action="count", default=-2,
                  help='Verbosity level : -v warning, -vv info, -vvv debug, (default info)')

    misc.add_argument('-f', '--overwrite', action="store_true", help='Overwrite existing files')   

    misc.add_argument('--progressbar',action="store_false",help="show progress bar") 
    
    return parser.parse_args()



  

def main(args):

    args = args() 
    logger = create_logger(args)
    config =json.load(open(files('jaegeraa.data').joinpath('config.json'), 'r'))
    logger.info(f"{version('jaeger')} Deep-learning based phage discovery\nhttps://github.com/Yasas1994/Jaeger.git\n\n" + "{:-^80}".format("validating parameters"))

    weights_path = files('jaegeraa.data').joinpath(config[args.model]['weights'])
    num_class = config[args.model]['num_classes']
    ood_params = None
    if not os.path.exists(weights_path):
        logger.error('Could not find model weights. Please check the data dir')
    # else:
    #    logger.info(f'Using {weights_path} to build the model')
    
    if config[args.model]['ood']:
        ood_weights_path = files('jaegeraa.data').joinpath(config[args.model]['ood'])
        hf = h5py.File(ood_weights_path, 'r')

        ood_params = {'coeff': np.array(hf['coeff']), 
                      'intercept' : np.array(hf['intercept']),
                      'mean_batch' : np.array(hf['mean_batch'], dtype='float16')}
        hf.close()
        
    if args.usecutoffs:
        cutoffs = config[args.model]['cutoffs']
        cutoffs = np.array([[cutoffs[str(i)] for i in range(len(cutoffs))]])
    else:
        cutoffs = None
    
    if args.getalllabels:
        config['labels'] = [v for k,v in config[args.model]['all_labels'].items()]
    else:
        config['labels'] = [v for k,v in config[args.model]['default_labels'].items()]

    # prepare output directory
    output_dir = args.output
    if not os.path.isdir(output_dir):
        os.mkdir(output_dir)
        logger.info(f"Output directory {output_dir} created.")
    else:
        logger.info(f"Using existing directory {output_dir}")

    #prepare output filename and check if exists
    input_file_path=args.input
    input_file = os.path.basename(input_file_path)
    if input_file.endswith('fna') or input_file.endswith('fasta') or input_file.endswith('txt') :
        output_file = f"{input_file.rsplit('.',1)[0]}_{config[args.model]['suffix']}_jaeger.tsv"
        output_file_path= os.path.join(output_dir,output_file)
        if os.path.exists(output_file_path):
            if not args.overwrite:
                logger.error("Outputfile exists. enable --overwrite option to overwrite the output file.")
                exit(1)
    else:
        logger.error("Input file is not a valid fastafile")
        exit(1)
    if args.progressbar:
        #disable progressbar
        tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)
        
    seed = 54920
    tf.random.set_seed(seed)
    # enables switching to a compatible GPU/CPU if the specified gpu is invalid 
    # tf.debugging.set_log_device_placement(True)
    # if cpu mode, hide all gpus available on the system
    gpus = tf.config.list_physical_devices('GPU')
    mode = None
    if args.cpu:
        mode = 'CPU'
        #visible devices can not be changed after initialization
        tf.config.set_visible_devices([], 'GPU')
        logger.info('CPU only mode selected')


    elif len(gpus) > 0:
        
        mode = 'GPU'
        tf.config.set_visible_devices([gpus[args.physicalid]], 'GPU')
        if args.virtualgpu:
            logger.info(f'Trying to create {gpus[args.physicalid]} a virtual GPU with 4096MB of mem ')
            # Create n virtual GPUs with user defined amount of memory each
            try:
                tf.config.set_logical_device_configuration(
                    gpus[args.physicalid],
                    [tf.config.LogicalDeviceConfiguration(memory_limit=4096,
                                                          experimental_device_ordinal=10) for i in range(1)])
                logical_gpus = tf.config.list_logical_devices('GPU')
                logger.info(logical_gpus)
                if len(logical_gpus) == 0:
                    logger.info('Failed to create virtual GPUs, switching back to single GPU mode')
            except Exception as e:
                # Virtual devices must be set before GPUs have been initialized
                logger.error(e)

        
    else:
        mode = 'CPU'
        logger.info("Could not find a GPU on the system.\nFor optimal performance run Jaeger on a GPU.")
        
    
    
    #psutil.virtual_memory().available * 100 / psutil.virtual_memory().total   

    logger.info(f'tensorflow : {version("tensorflow")}')
    logger.info(f'Input file : {input_file}')
    logger.info(f'Fragment size : {args.fsize}')
    logger.info(f'Stride : {args.stride}')
    logger.info(f'Batch size : {args.batch}')
    logger.info(f'Mode : {mode}')
    logger.info(f'Total Mem : {psutil.virtual_memory().available/(1024.0 ** 3) : .2f}GB')
    logger.info(f'Avail cpus : {os.cpu_count()}')

    input_fh = get_compressed_file_handle(input_file_path)
    num = fasta_entries(input_fh)
    device = tf.config.list_logical_devices(mode)
    device_names = [get_device_name(i) for i in device]
    logger.debug(f'{device}, {device_names}')

    if len(device) > 1:
        logger.info(f'Using MirroredStrategy {device_names}')
        strategy = tf.distribute.MirroredStrategy(device_names)
    else:
        logger.info(f'Using OneDeviceStrategy {device_names}')
        strategy = tf.distribute.OneDeviceStrategy(device_names[0])

    tf.config.set_soft_device_placement(True)
    with strategy.scope():

        input_dataset = tf.data.Dataset.from_generator(fasta_gen(input_fh,fragsize=args.fsize,stride=args.stride,num=num, disable=args.progressbar),
                                                        output_signature=(tf.TensorSpec(shape=(), dtype=tf.string)))
        if args.model == "default":
            idataset=input_dataset.map(process_string(crop_size=args.fsize),
                                        num_parallel_calls=tf.data.AUTOTUNE,).batch(args.batch, 
                                        num_parallel_calls=tf.data.AUTOTUNE).prefetch(25)
            inputs, outputs = WRes_model(input_shape=(None,))
            model = JaegerModel(inputs=inputs, outputs=outputs)
            
        else:
            insize = (int(args.fsize)//3)-1 
            idataset=input_dataset.map(process_string_gen2(crop_size=args.fsize),
                            num_parallel_calls=tf.data.AUTOTUNE,).padded_batch(args.batch, 
                            padded_shapes=(({
                                    #'nucleotide': [2,int(args.fsize),4], 
                                    'translated': [6,insize,11], },(),(),(),(),()))).prefetch(50)
                  
                      
            inputs, outputs  = create_jaeger_model(input_shape=(6,insize,11),out_shape=num_class)
            model = JaegerModel(inputs=inputs, outputs=outputs)
        
        model.load_weights(filepath=weights_path)#.expect_partial() when loading weights from a chpt file

        logger.info(f"Model initialized ... ")
        logger.info(f'Avail Mem : {psutil.virtual_memory().available/(1024.0 ** 3) : .2f}GB\n{"-"*80}')

        
        if mode == 'GPU':
            for device_number,d in enumerate(device_names):
                gpu_mem = tf.config.experimental.get_memory_info(d)
                logger.info(f'GPU {device_number} current : {gpu_mem["current"]/(1024.0 ** 2) : .2f} GB  peak : {gpu_mem["peak"]/(1024.0 ** 2) : .2f}GB')
        

        try:
            y_pred = model.predict(idataset, workers=args.workers, verbose=0)
        except Exception as e:
            logger.error(f'Annother process is running on {"|".join(device_names)}! Terminate the process and try again or switch to CPU mode!!')
            sys.exit(1)

        split_indices = np.where(np.array(y_pred['meta'][2], dtype=np.int32) == 1)[0]+1
        if y_pred['y_hat']['output'].shape[0] == split_indices[-1]:
            split_indices = split_indices[:-1]
        print(y_pred['y_hat']['output'])
        predictions = np.split(y_pred['y_hat']['output'], split_indices, axis=0)
        headers = np.split(np.array(y_pred['meta'][0], dtype=np.unicode_),split_indices, axis=0)
        lengths = np.split(np.array(y_pred['meta'][4], dtype=np.int32),split_indices, axis=0)
        lengths = np.array(list(map(lambda x : x[0], lengths)))
        headers = np.array(list(map(lambda x : x[0], headers)))
        pred_sum = np.array(list(map(lambda x: np.mean(x,axis=0),predictions)),np.float16)
        pred_std = np.array(list(map(lambda x: np.std(x,axis=0),predictions)),np.float16)
        consensus = np.argmax(pred_sum, axis=1)
        frag_pred = list(map(lambda x: np.argmax(x,axis=-1),predictions))
        per_class_counts = list(map(lambda x : np.unique(x, return_counts=True),frag_pred))
        per_class_counts = list(map(lambda x,n=config[args.model]['num_classes'] : update_dict(x,n) , per_class_counts))


        data = {'headers':headers, 'length' : lengths,
                'consensus':consensus,'per_class_counts' : per_class_counts,
                'pred_sum':pred_sum, 'pred_std':pred_std, 'frag_pred':frag_pred }

        write_output(args, config, data, output_file_path)

        logger.info(f"processed {headers.shape[0]}/{num} sequences \n" )

        if args.getalllogits:
            output_logits = f"{input_file.rsplit('.',1)[0]}_jaeger.npy"
            output_logits_path= os.path.join(output_dir,output_logits)
            np.save(output_logits_path,dict(zip(headers, predictions)), allow_pickle=True)
    
        if args.prophage:
            # alpha version - needs more testing!!!!
            try:
                logits_df = logits_to_df(predictions, headers=headers, lengths=lengths, cutoff_length = args.lc)
                if logits_df:
                    logger.info(f"Identifying prophage regions")
                    pro_dir = os.path.join(output_dir,f'{os.path.basename(input_file).split(".")[0]}_prophages')
                    plots_dir = os.path.join(pro_dir,'plots')
                    for dir in [pro_dir,plots_dir]:
                        if not os.path.isdir(dir):
                            os.mkdir(dir)
 
                    
                    plot_scores(logits_df, outdir=plots_dir)
                    phage_cord = segment(logits_df, outdir=plots_dir, cutoff_length = args.lc, sensitivity=args.sensitivity)
                    get_cordinates(args.input, phage_cord, pro_dir)
                else:
                    logger.info(f"No prophage regions found")
            except Exception as e:
                logger.exception(e)
                remove_directory(pro_dir)

if __name__ == "__main__":
    main(cmdparser)
     
 
